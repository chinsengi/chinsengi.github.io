<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2026-01-06T09:18:34+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Shirui (Carl) Chen</title><subtitle>Ph.D. Candidate in Applied Mathematics at University of Washington</subtitle><author><name>Shirui (Carl) Chen</name><email>sc256@uw.edu</email></author><entry><title type="html">如何求解 $\dot{x} = x+f(t)$</title><link href="http://localhost:4000/posts/2021/09/diffeqsolve/" rel="alternate" type="text/html" title="如何求解 $\dot{x} = x+f(t)$" /><published>2021-09-29T00:00:00+00:00</published><updated>2021-09-29T00:00:00+00:00</updated><id>http://localhost:4000/posts/2021/09/diffeqsolve</id><content type="html" xml:base="http://localhost:4000/posts/2021/09/diffeqsolve/"><![CDATA[<p>最近在看Dayan和Abbott的<a href="https://mitpress.mit.edu/books/theoretical-neuroscience" rel="noopener" target="_blank"><em>Theoretical
Neuroscience</em></a>。虽然是数学系学生但是由于太浪，分析代数几何都学了个遍，感觉哪科都没学好，于是后遗症就是像傅里叶变换这种极为重要的东西竟然不是很熟。
于是我决定先把书后面的数学Appendix先光速过一遍，以免在读正文的时候尴尬卡壳。在附录讲微分方程的部分有一个方程：
\(\begin{equation}
C\frac{dV}{dt} = \frac{E-V}{R} + I_e
\end{equation}\) 这是比较容易求解的，令$W =
-V+E+RI_e$, 我们有 \(\begin{equation}
RC(-W)' = W
\end{equation}\) 愉快地分离变量就能得到$W =
C’\exp(-t/\tau)$. 把$V(0)$ 这个初始条件代进去就有$C’ = W(0) = -V(0)+E+RI_e$。
我们就能得到书上列出的解 \(\begin{equation}
V(t) = V\_\inf +(V(0)- V\_\inf) \exp(-t/\tau)
\end{equation}\)</p>

<p>[]{#more}</p>

<p>其中$V_\inf = E+RI_e$, $\tau =
RC$。接下来作者又假设了另外一种情况， 这种情况下$I_e$ 随时间振荡： $I_e = I\cos(\omega t)$.
这下就有点难办，不过没关系，把我们的意大利炮拉上来: 对于方程 $\dot{x} = a(t)x+b(t)$, 我们有解 \(\begin{equation}
x(t) = \exp\left(\int_0^t a(s)\,ds\right)x(0)+\int_0^t
\exp\left(\int_s^t a(r)\,dr\right)b(s)\,ds
\end{equation}\label{eq:1}\tag{1}\) 这个方程是这样解的， 两边同乘$\mu(t) = \exp(-\int_0^t a(s) ds)$
(别问我为啥是这个，问就是exponential的derivative可以把指数拿下来然后用链式法则，就硬凑)。这样方程就变成了
\(\begin{equation}
\begin{split}
\mu(t)\dot{x} - \mu(t)a(t)x&amp;= b(t)\mu(t)\\
\left(\mu(t)x\right)' &amp;= b(t)\mu(t)\\
\mu(t)x &amp;=\int_0^t b(r)\mu(r)dr+C\\
\end{split}
\end{equation}\)</p>

<p>把$t = 0$带进去, 发现$C = x(0)$, 把$\mu(t)$
移到另一边，我们就得到了之前那个解$\eqref{eq:1}$。直接把答案代到方程里面验算当然也可以证明，但那就是明目张胆的作弊了。而且应该会用到<a href="https://en.wikipedia.org/wiki/Leibniz_integral_rule" rel="noopener" target="_blank">Leibniz
integral rule</a>。接下来我们，开炮！我们把$V$当成$x$, $a(t) =
-1/\tau$, $b(t) = E/\tau+I\cos(\omega
t)/C$, 所以解就是 \(\begin{equation}
V(t) = e^{-t/\tau}V(0)+\int_0^t e^{-(t-s)/\tau}b(s)ds
\end{equation}\)</p>

<p>可能大家读到这里都忘了我们是在解一本书里面的方程，书上是这么说的,
"once an initial transient has decayed to zero, we find" \(\begin{equation}
V(t) = E+\frac{RI\cos(wt- \phi)}{ \sqrt{1+\omega^2 \tau^2} }
\end{equation}\) 其中$\tan(\phi) =
\omega\tau$。啊这。。。我刚开始看的时候是懵逼的，啥是transient?
后来才知道可能这是电子工程里面的术语。
Transient的意思不是短暂的么，这里就是指在$t\to \inf$时趋于0的项，
可以想象成时间长了后散逸掉的能量。我们相当于要求下面这个东西 \(\lim\_{t\to\inf} \int_0^t e^{-(t-s)/\tau}b(s)ds\) 这里的极限不是分析意义上的，只是表示去掉$t\to \inf$时为0的项。东凑凑西算算，
最后发现还是把余弦化成复数形式会比较好： \(\begin{equation}
\cos(\omega t) = \frac{\exp(iwt)+\exp(-iwt)}{2}
\end{equation}\)</p>

<p>目的当然是好积分， 并不清楚作者是如何算的 \(\begin{split}
\int_0^te^{-(t-s)/\tau}(E/\tau+I\cos(\omega s)/C)ds &amp;= A(t)+B(t)+C(t)\\
A(t)&amp;=\frac{E}{\tau}\int_0^t e^{-(t-s)/\tau}ds\\
B(t)&amp;= \frac{I}{2C}\int_0^t\exp(iws-(t-s)/\tau)ds\\
C(t)&amp;= \frac{I}{2C}\int_0^t\exp(-iws-(t-s)/\tau)ds
\end{split}\) 简单的积分: \(\begin{split}
A(t) &amp;= E(1-e^{-t/\tau})\\
B(t) &amp;= \frac{I\tau}{2C(iw\tau +1)}(\exp(iwt) - \exp(-t/\tau))\\
C(t) &amp;= \frac{I\tau}{2C(-iw\tau +1)}(\exp(-iwt) - \exp(-t/\tau))\\
\end{split}\) 求个”极限” \(\begin{split}
\lim\_{t\to\inf} A(t) &amp;= E\\
\lim\_{t\to\inf} B(t) &amp;=\frac{I\tau}{2C(iw\tau +1)}\exp(iwt)\\
\lim\_{t\to \inf}C(t) &amp;= \frac{I\tau}{2C(-iw\tau +1)}\exp(-iwt)\\
\end{split}\) 别忘了$\tau = RC$,
于是我们有 \(V(t) = E+\frac{RI\left[\exp(iwt)(-iw\tau+1)+\exp(-iwt)(iw\tau+1)\right]}{2(
1+\omega^2 \tau^2)}\) 把指数再展开成三角函数 \(V(t) = E+\frac{RI(\cos(w\tau)+w\tau \sin(w\tau) )}{1+w^2\tau^2}\)
诶和书上的答案不一样，gg。小丑竟是我自己。其实是这样，观察分子和 \(\cos(\alpha-\beta) = \cos(\alpha)\cos(\beta)+\sin(\alpha)\sin(\beta)\) 的相似性， 我们希望 \(\begin{split}
\cos(\phi) = 1\\
\sin(\phi) = w\tau
\end{split}\) 这不可能，平方和要是1，于是上下同除$1/\sqrt{1+w^2\tau^2}$即可。 \(\begin{split}
\cos(\phi) = 1/\sqrt{1+w^2\tau^2}\\
\sin(\phi) = w\tau/\sqrt{1+w^2\tau^2}
\end{split}\) $\tan(\phi) =
w\tau$自然成立。到此我们终于得到了这个书上没有过程的结论。。。</p>

<p>后记：打这篇文章主要是想体验一下在博客里面写有大量公式的文章的体验。
有macro确实爽。不过打latex得不断切换中英输入法很麻烦，下次用英语写得了。</p>]]></content><author><name>Shirui (Carl) Chen</name><email>sc256@uw.edu</email></author><category term="math" /><category term="differential equation" /><summary type="html"><![CDATA[最近在看Dayan和Abbott的Theoretical Neuroscience。虽然是数学系学生但是由于太浪，分析代数几何都学了个遍，感觉哪科都没学好，于是后遗症就是像傅里叶变换这种极为重要的东西竟然不是很熟。 于是我决定先把书后面的数学Appendix先光速过一遍，以免在读正文的时候尴尬卡壳。在附录讲微分方程的部分有一个方程： \(\begin{equation} C\frac{dV}{dt} = \frac{E-V}{R} + I_e \end{equation}\) 这是比较容易求解的，令$W = -V+E+RI_e$, 我们有 \(\begin{equation} RC(-W)' = W \end{equation}\) 愉快地分离变量就能得到$W = C’\exp(-t/\tau)$. 把$V(0)$ 这个初始条件代进去就有$C’ = W(0) = -V(0)+E+RI_e$。 我们就能得到书上列出的解 \(\begin{equation} V(t) = V\_\inf +(V(0)- V\_\inf) \exp(-t/\tau) \end{equation}\)]]></summary></entry><entry><title type="html">Sprague-Grundy Theorem and the Game of Nim</title><link href="http://localhost:4000/posts/2021/07/sprague-grundy-theorem-and-the-game-of-nim/" rel="alternate" type="text/html" title="Sprague-Grundy Theorem and the Game of Nim" /><published>2021-07-18T00:00:00+00:00</published><updated>2021-07-18T00:00:00+00:00</updated><id>http://localhost:4000/posts/2021/07/Sprague-Grundy-Theorem-and-the-Game-of-Nim</id><content type="html" xml:base="http://localhost:4000/posts/2021/07/sprague-grundy-theorem-and-the-game-of-nim/"><![CDATA[<p>Halo, recently I reacquainted myself with the Sprague-Grundy theorem
and would like to introduce the gist of it. I think <a href="https://en.wikipedia.org/wiki/Sprague%E2%80%93Grundy_theorem" rel="noopener" target="_blank">Wikipedia</a>
does a great job explaining the detailed proof, but I would like to fill
in some gaps and provide some intuitions. It is recommended to read
about the rule of the game of nim (and the wiki page if you are
interested in technical details) before reading.</p>

<p>Basically the theorem says that every impartial game is equivalent to
a game of nim with a pile of $n$
stones. The number $n$ is called the
Grundy number of the impartial game. Now there are two things to
explain.</p>

<ol>
  <li>impartial game means that both players of the game have the same set
of operations given a fixed position of the game. Chess and Go are not
impartial games, because one player can only move or place pieces that
have the same color (either black or white).</li>
  <li>What does it mean that two games $G$ and $G’$are "equivalent"? One may give a
definition stating that if one game has a winning strategy for the
player that goes first (or the second player), so does the equivalent
game and vice versa. However, having this condition is not enough.
Consider any game that has a winning strategy for the second player.
Clearly every nim game with non-zero number of stones is equivalent to
that game, making Grundy number an ill-defined number. Therefore, we
additionally require that the combined games of $G+H$ and $G’+H$ have winning strategies for the
same player for any given impartial game $H$.</li>
</ol>

<p>Now the Sprague-Grundy theorem gives a recursive definition of what
the Grundy number of any given impartial game is: Suppose we can go from
the current position $G_0$ of the
game to $k$ other positions, ${G_1, G_2, \dots, G_k}$, and each of
$G_i$ is equivalent to the game of
nim with $n_i$ stones. Then $G_0$ is equivalent to the game of nim with
$n_0$ stones given by \(n_0 = \text{mex}(n_1, n_2,\dots, n_k)\) Here $\text{mex}(A)$ for
some non-negative integer set $A$ is
the smallest non-negative integer that is not in $A$.</p>

<p>This is useful, but not that useful, consider a game of nim consists
of multiple heaps of stones, where i-th heap has $n_i$ stones. How do we determine the
Grundy number and whether we have a winning strategy for the game? If we
still use the recursive definition, we will have $\prod n_i$ states to calculate, which can
be huge. This is where bit xor operation comes to rescue!</p>

<p>In the following we will consider just one quantity: the xor of all
numbers of stones in each heap, i.e. $Q =
\bigoplus n_i$. Let’s consider the game bottom-up. Which
position will the losing player face at the end? Obviously, the position
where no stone is left, and $Q = \bigoplus 0
= 0$. It turns out that the winning strategy is to keep leaving
the opponent with a position where $Q =
0$! In order to show that, we have to show two things</p>

<ol>
  <li>If right now $Q = 0$, any valid
operation will lead to a position where $Q\neq 0$.</li>
  <li>If right now $Q\neq 0$, there is
always a valid operation that can lead to a position where $Q = 0$</li>
</ol>

<p>The first statement is easy. Consider you are moving the $k$-th heap. Since we have $Q = (\bigoplus_{i\neq k} n_i) \oplus n_k =
0$, i.e. $\bigoplus_{i\neq k} n_i =
n_k$ right now, changing the number of stones in heap $k$ will make $Q$ not equal to 0.</p>

<p>The second statement: First we convert everything into numbers with
base of 2 and fill in zeros so that every $n_i$ has the same length. Consider the
left-most digit of $Q$ that is not 0,
say it is $m$-th digit from the left.
Since $Q$ is 1 at $m$, we can pick $n_k$ such that $n_k$ has 1 at that position. Now since
$\bigoplus_{i\neq k} n_i$ has 0 at
that position, we can set $n_k$ to
$\bigoplus_{i\neq k} n_i$. To see
that this value is strictly smaller than $n_k$, simply note that both have the same
$1$st to $(m-1)$-th digits.</p>

<p>So the winning strategy exists for the first player if we start off
with a non-zero $Q$, and for the
second player if we start off with $Q =
0$. One more thing: how do we show that the Grundy number is
exactly $Q$, instead of any non-zero
number in the case of non-zero $Q$?
This actually follows from the conclusion of the theorem. Let’s consider
a simplified case where there are only two heaps. Situations where there
are 3 or more heaps can be reduced by merging two of them at a time.
Following the notation convention in Wikipedia, we denote a single heap
nim game of size $n$ as ${*n}$. We want to show that ${*a}+{*b}\equiv {*(a\oplus
b)}$, i.e. the combined game of two single heap nim games is
equivalent to one single heap nim game in the sense defined in the
theorem. From the theorem we know that 
\(\{*a\}+\{*b\}\equiv \text{mex}\left(\bigcup_{i = 0}^{a-1}
(\{*i\}+\{*b\})\cup\bigcup_{j =
0}^{b-1}(\{*a\}+\{*j\})\right):=\text{mex}(A)\) 
By induction on $a+b$, we
assume that ${*i}+{*b}\equiv
{*(i\oplus b)}$ and the inductive hypothesis holds. To see that the right hand
side is exactly $a\oplus b$, we note
that</p>

\[\begin{split}
i\oplus b\oplus a\oplus b &amp;= i\oplus a \neq 0\\
a\oplus j\oplus a\oplus b &amp;= j\oplus b \neq 0\\
i\oplus b\oplus i'\oplus b &amp;= i\oplus i'\\
a\oplus j\oplus a\oplus j' &amp;= j\oplus j'
\end{split}\]

<p>i.e. no element in $A$ is
equal to $a\oplus b$. Moreover, there
are at least $\max(a,b)$ different
elements in $A$. The result follows,
because $a\oplus b \leq \max(a,b)$.
It’s left to check the base cases, but they are trivial, so we are done.
$\blacksquare$</p>

<p>Now the Grundy theorem is much more practically useful, since it can
deal with games that have multiple component games efficiently. Remember
that each component game is equivalent to a single heap nim game!</p>

<p>Coding time! <a href="https://atcoder.jp/contests/abc206/tasks/abc206_f" rel="noopener" target="_blank">Here</a> is a
sample problem. Consider the game to be played on interval $[1,100]$, and choosing an interval results
in a position that can be split into two component games. For each
position we can apply the bit xor operation to get the Grundy number.
Applying the mex function to Grundy numbers of all positions gives the
answer.</p>

<figure class="highlight c++">
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="odd">
<td class="gutter"><pre><code>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40</code></pre></td>
<td class="code"><pre><code>#include&lt;bits/stdc++.h&gt;
using namespace std;
#define rep(i,s,n) for(int i = s; i &lt; n; i++)
   
int T; int N; typedef pair&lt;int, int&gt; ii;
vector<ii> intervals;
const int maxn = 105;
int dp[maxn][maxn];

int recur(int st, int end){
    if(st&gt;=end) return dp[st][end] = 0;
 if(dp[st][end]!=-1) return dp[st][end];
    int all[maxn]; memset(all,0,sizeof all);
 for(auto&amp; p : intervals)if(p.first&gt;=st&amp;&amp; p.second&lt;=end){
        int a = recur(st, p.first);
       int b = recur(p.second, end);
     int res = a^b; // merge two component games
        if(res&lt;maxn) all[res] = 1;
   }
    rep(i,0,maxn)if(all[i]==0){ // calculate the mex
     return dp[st][end] = i;
 }
}
    
int main(){
 cin&gt;&gt;T;
    while(T--){
     cin&gt;&gt;N;
        intervals.clear();
     rep(i,0,N) {
           int l,r;cin&gt;&gt;l&gt;&gt;r;
          intervals.push_back({l,r});
        }
        memset(dp, -1, sizeof dp);
        if(recur(1,100)!=0)cout&lt;&lt;"Alice"&lt;&lt;endl;
       else cout&lt;&lt;"Bob"&lt;&lt;endl;
 }
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/figure&gt;
</ii></code></pre></td></tr></tbody></table></figure>]]></content><author><name>Shirui (Carl) Chen</name><email>sc256@uw.edu</email></author><category term="Competitive Programming" /><category term="Game Theory" /><category term="Combinatorics" /><summary type="html"><![CDATA[Halo, recently I reacquainted myself with the Sprague-Grundy theorem and would like to introduce the gist of it. I think Wikipedia does a great job explaining the detailed proof, but I would like to fill in some gaps and provide some intuitions. It is recommended to read about the rule of the game of nim (and the wiki page if you are interested in technical details) before reading.]]></summary></entry><entry><title type="html">Chinese Remainder Theorem</title><link href="http://localhost:4000/posts/2021/07/chinese-remainder-theorem/" rel="alternate" type="text/html" title="Chinese Remainder Theorem" /><published>2021-07-01T00:00:00+00:00</published><updated>2021-07-01T00:00:00+00:00</updated><id>http://localhost:4000/posts/2021/07/Chinese-Remainder-Theorem</id><content type="html" xml:base="http://localhost:4000/posts/2021/07/chinese-remainder-theorem/"><![CDATA[<p>I recently decided to pick up competitive programming, not only
because I enjoy programming, but also because this is a fail safe for my
academic career. With the tension between China and US rises, any
Chinese research personnel in the US is bound to be persecuted in one
way or another (it already begins with the visa application). It will be
increasingly risky to put all the eggs in one basket. And the recent <a href="https://www.universityworldnews.com/post.php?story=20210611084120155" rel="noopener" target="_blank">Wenhua
Jiang Incident</a> further dims the light on the path to tenure in China
for many researchers. So in short, doing competitive programming is an
act of interest (pun intended).</p>

<p>So much gibberish, today we are going to talk about Chinese Remainder
Theorem, which basically says that given a set of coprime integers, and
we know the remainders of an unknown integer modulo those coprime
numbers, then the smallest such unknown number can be uniquely
determined. For a rigorous definition, see <a href="https://en.wikipedia.org/wiki/Chinese_remainder_theorem" rel="noopener" target="_blank">wiki</a>.
The proof is quite simply, say the set of coprime numbers are $n_1, n_2, \dots, n_k$, and $N = \Pi_i n_i$. And the aforementioned
remainders are $r_1, r_2, \dots,
r_k$. We only consider integers in the range $[1, N]$. The key observation is that if
two <em>different</em> numbers have the same set of remainders, the
absolute difference between them will be divisible by all $n_i$ s, and since the difference is capped
by $N-1$, it is zero, contradiction!
Therefore a one-to-one correspondence can be established between each
integer within that range and a set of all possible remainders. Note
that the range of each $r_i$ is $[0, r_i-1]$, so both sides have the same
cardinality.</p>

<p>Now let’s look at implementation of this theorem in competitive
programming. An example problem is <a href="https://atcoder.jp/contests/abc193/tasks/abc193_e" rel="noopener" target="_blank">here</a>. So
the problem is to solve the following set of congruence equations \(x \equiv a_1 \pmod{m_1}\\
x\equiv a_2 \pmod{m_2}\) which is equivalent to \(x = a_1+n_1 m_1 = a_2+n_2m_2\) for some integer $n_1$ and
$n_2$, i.e. \(\begin{equation}
a_2 - a_1 = n_1m_1 - n_2m_2 \tag{1} \label{eq:1}
\end{equation}\) We can use extended Euclidean algorithm to solve for $n_i$ given $m_i$ in the following equation \(\begin{equation}
n_1m_1 - n_2m_2 = \gcd(m_1, m_2) := d \tag{2}\label{eq:2}
\end{equation}\) <em>Detour (please skip at will)</em>: There is a proof of
existence of an integer solution that I really like about the above
equation. Since we can divide both sides by $\gcd(m_1, m_2)$, we can just deal with the
case $n_1m_1 - n_2m_2 = 1$ where
$m_1$ and $m_2$ are coprime to each other. Now here
is the clever proof: Let $r$ be the
smallest positive integer such that $n_1m_1 -
n_2m_2 = r$ has an integer solution. And we can express $m_1$ as multiple of $r$ plus a remainder term, i.e. $m_1 = q_1r+r_1$. So the equation becomes
\(n_1m_1 - n_2m_2 = r = (m_1 - r_1)/q_1\) Some algebra shows that $(1-q_1n_1)m_1+n_2q_1m_2 = r_1$, note that
$r_1$, as a remainder of division by
$r$, is strictly smaller than $r$. So there is only one possibility:
$r_1 = 0$. So $m_1$ is actually a multiple of $r$ ! By symmetry, $m_2$ is a multiple of $r$ as well. However since $m_1$ and $m_2$ are coprime, $r $ can only be 1. Note
that this is effectively a proof of existence since such smallest $r$ must exist as everything here is
finite. $\blacksquare$</p>

<p>Now if $d\nmid a_1 - a_2$, then we
can already claim that the pair of congruent equations have no solution.
If otherwise, we can multiply both sides of $\eqref{eq:2}$ by $(a_2 - a_1)/d$ to get $\eqref{eq:1}$. For equation sets that
contain 3 or more equations, we can process and merge two of them at a
time</p>

<p>Coding time!</p>

<figure class="highlight c++">
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="odd">
<td class="gutter"><pre><code>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19</code></pre></td>
<td class="code"><pre><code>typedef long long ll;
//extended euler's algorithm
void gcd(ll a, ll b, ll&amp; d, ll&amp; x, ll&amp; y){
   if(!b){d  = a; x = 1; y = 0;}
   else {gcd(b, a%b, d, y, x); y -= (a/b)*x;}
}

ll china(int n, ll* a, ll* m){
  ll d,y,x = 0;
    rep(i,0,n-1){
      gcd(m[i],m[i+1],d,x,y);
        if((a[i+1] - a[i])%d!=0) return -1;
        a[i+1] = a[i]+((x*((a[i+1] - a[i])/d))%(m[i+1]/d))*m[i];
     m[i+1] = m[i]*(m[i+1]/d);
        a[i+1] = a[i+1]%m[i+1];
  }
    ll M = m[n-1];
   return (a[n-1]+M)%M;
}</code></pre></td>
</tr>
</tbody>
</table>
</figure>

<p>The extended Euler’s algorithm can be implemented by just two lines
of C++, pretty surprising, isn’t it? One last thing to note, as there is
a 10\^18 numeric limit in most competitive programming contest, we need
to handle the overflow problem using $c(a\pmod{b})\equiv ca \pmod{cb}$ in the
following line of code</p>

<figure class="highlight c++">
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<tbody>
<tr class="odd">
<td class="gutter"><pre><code>1</code></pre></td>
<td class="code"><pre><code>a[i+1] = a[i]+((x*((a[i+1] - a[i])/d))%(m[i+1]/d))*m[i];</code></pre></td>
</tr>
</tbody>
</table>
</figure>

<p>That’s it, happy coding until next time!</p>

<h6 id="reference">Reference</h6>

<p><a href="https://codeforces.com/blog/entry/61290" rel="noopener" target="_blank">[Tutorial] Chinese
Remainder Theorem - Codeforces</a></p>]]></content><author><name>Shirui (Carl) Chen</name><email>sc256@uw.edu</email></author><category term="Competitive Programming" /><category term="Chinese Remainder Theorem" /><summary type="html"><![CDATA[I recently decided to pick up competitive programming, not only because I enjoy programming, but also because this is a fail safe for my academic career. With the tension between China and US rises, any Chinese research personnel in the US is bound to be persecuted in one way or another (it already begins with the visa application). It will be increasingly risky to put all the eggs in one basket. And the recent Wenhua Jiang Incident further dims the light on the path to tenure in China for many researchers. So in short, doing competitive programming is an act of interest (pun intended).]]></summary></entry><entry><title type="html">Limit of Binomial Distribution</title><link href="http://localhost:4000/posts/2021/06/limit-of-binomial-distribution/" rel="alternate" type="text/html" title="Limit of Binomial Distribution" /><published>2021-06-19T00:00:00+00:00</published><updated>2021-06-19T00:00:00+00:00</updated><id>http://localhost:4000/posts/2021/06/Limit-of-Binomial-Distribution</id><content type="html" xml:base="http://localhost:4000/posts/2021/06/limit-of-binomial-distribution/"><![CDATA[<p>In computational neuroscience, Poisson distribution is very important
in that spike trains are usually modeled as a Poisson process. This
article demonstrates that the Poisson distribution can be obtained as a
limit of Binomial Distribution.</p>

<p>Consider a time interval $[0,T]$
in which spikes occur. Let’s assume that $k$ spikes occur within that interval. Now
we divide the interval into $n$ bins,
and within each time bin, a spike occurs with probability $p$. Note that we only allow one spike per
bin. So the probability of having $k$
spikes within $[0,T]$ is \(P(k) = {n\choose k}p^k(1-p)^{n-k}\) Now this is the probability mass function of binomial
distribution. If we take the limit of $n\to
\inf$, we quickly find that the result is zero. This is because
it is upper-bounded by $n^k (1-p)^n$
times a constant. It suffices to show that $n\alpha^n\to 0$ as $n\to \inf$, where $0&lt;\alpha&lt;1$. Simply note that $n\alpha^{n-1}$ is the derivative of $\alpha^n$ which goes to 0 as $n$ goes to infinity. So we can always
choose large enough $n$ such that any
finite difference of $\alpha^n$ around
$\alpha$ is below any small $\varepsilon$, QED.</p>

<p>The question now is how do we take the limit in a proper sense so
that the result is the probability mass function of Poisson
distribution. We introduce a new concept called the firing rate $r$, which indicates how often the neuron
fires with the time interval $[0,T]$.
Here is the key insight: as $n$
grows, each time bin gets smaller and smaller, so the probability of a
spike occurring $p$ is also
increasingly smaller. More specifically, they are related by $\lambda:=rT = np$.</p>

<p>Now here is the mathematical show: 
\(\begin{split}
\lim_{\lambda = np,\ n\to \inf}P(k) &amp;= \lim_{rT = np,\ n\to
\inf}\frac{n!}{k!(n-k)!}(\lambda/n)^k(1-\lambda/n)^{n-k}\\
&amp;=\lim_{\lambda = np,\ n\to
\inf}\frac{n!}{k!(n-k)!}(\lambda/n)^k(1-\lambda/n)^{-k}((1-\lambda/n)^{-n/\lambda})^{-\lambda}\\
&amp;=\lim_{\lambda = np,\ n\to
\inf}\frac{n!}{k!(n-k)!}\frac{\lambda^k}{(n-\lambda)^k}\exp(-\lambda)\\
&amp;=\frac{\lambda^k}{k!}\exp(-\lambda)
\end{split}\)</p>

<p>In the intermediate step we use the definition of Euler’s
number $e$, and we arrive at the
probability mass function of Poisson Distribution. We are done, have a
nice day :)</p>]]></content><author><name>Shirui (Carl) Chen</name><email>sc256@uw.edu</email></author><category term="math" /><category term="Poisson" /><summary type="html"><![CDATA[In computational neuroscience, Poisson distribution is very important in that spike trains are usually modeled as a Poisson process. This article demonstrates that the Poisson distribution can be obtained as a limit of Binomial Distribution.]]></summary></entry></feed>